{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navya003/NLP/blob/main/RFclassifier_randomsearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTbC8L_XcU_j",
        "outputId": "8d7bfff2-1f1a-4d9f-a5ac-5e4f871b1010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of base model: 80.09%\n",
            "Parameters currently in use:\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': 1,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 200,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 42,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n",
            "Range of parameters used for hyperparameter tuning:\n",
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        }
      ],
      "source": [
        "# RF classifier model\n",
        "# Random search implementation\n",
        "# imported the required modules\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from pprint import pprint\n",
        "# Module for hyperparameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# loaded the dna2vec word embedding file data\n",
        "# opened and read the respective files\n",
        "f_pos=open('Positive.w2v','r')\n",
        "f_neg=open('Negative.w2v','r')\n",
        "file_p=f_pos.read()\n",
        "file_n=f_neg.read()\n",
        "# took file content as a list of sequences\n",
        "# seperated by newline according to the indexing\n",
        "lis_p=[x.split() for x in file_p.split('\\n')[1:-1]]\n",
        "lis_n=[x.split() for x in file_n.split('\\n')[1:-1]]\n",
        "# converted the sequence values(string) into numerical values(float)\n",
        "list_p=[[float(x) for x in y[1:]] for y in lis_p]\n",
        "list_n=[[float(x) for x in y[1:]] for y in lis_n]\n",
        "# labelled natural sequence embeddings as 1\n",
        "l_pos=[x+[1] for x in list_p]\n",
        "# labelled synthetic sequence embeddings as 0\n",
        "l_neg=[x+[0] for x in list_n]\n",
        "# merged both the lists together\n",
        "l_whole = l_pos+l_neg\n",
        "# converted the list to arrray for model implementation\n",
        "dataset = np.array([np.array(x) for x in l_whole])\n",
        "\n",
        "# split data into X and Y\n",
        "X = dataset[:,:-1]\n",
        "Y = dataset[:,-1]\n",
        "\n",
        "# split the data into train and test using sklearn\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
        "# test_size defines test data to be split from train data\n",
        "\n",
        "# RF classifier model\n",
        "classifier=RandomForestClassifier(n_estimators=200, random_state=42, max_depth=1)\n",
        "\n",
        "# fit the training data into the model\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# predicted values from the model\n",
        "y_pred=classifier.predict(x_test)\n",
        "\n",
        "# accuracy prediction for base model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of base model: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "# confusion matrix\n",
        "conf=confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix\\n\", conf)\n",
        "\n",
        "# classification report\n",
        "print(\"Classification report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Look at parameters used by our current forest\n",
        "print('Parameters currently in use:')\n",
        "pprint(classifier.get_params())\n",
        "\n",
        "# Hyperparameter tuning using RandomizedsearchCV\n",
        "# Setting range of parameters\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "param = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "print('Range of parameters used for hyperparameter tuning:')\n",
        "pprint(param)\n",
        "\n",
        "# implemented grid search on RF classifier\n",
        "classifier_random=RandomizedSearchCV(estimator = classifier, param_distributions = param, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "# fit the training data\n",
        "classifier_random.fit(x_train, y_train)\n",
        "\n",
        "# Best hyperparameter values\n",
        "print('Best parameter values:')\n",
        "classifier_random.best_params_\n",
        "\n",
        "# predicted values from the random search model\n",
        "pred=classifier_random.predict(x_test)\n",
        "\n",
        "# accuracy prediction for random search model\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "print(\"Accuracy of random search model: %.2f%%\" % (accuracy * 100.0))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6Mbqu45xsLBgenTNeoN8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}